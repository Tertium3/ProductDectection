{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np \n",
    "from sklearn.decomposition import PCA\n",
    "import skimage as sk\n",
    "from skimage import transform\n",
    "from skimage import util\n",
    "from skimage import io\n",
    "from scipy import ndarray\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All path should be constructed by join function\n",
    "\n",
    "#To resize all images in a given folder path and save with the same name.\n",
    "#Params\n",
    "# path: folder path contains image set\n",
    "# size: image will be resize to (size, size)\n",
    "def resize(path, size):\n",
    "    for filename in glob.glob(\"{}/*.jpg\".format(path)):\n",
    "        image = Image.open(filename)\n",
    "        new_image = image.resize((size, size))\n",
    "        new_image.save(filename)\n",
    "\n",
    "#Load data from given folder path as list of image in RGB format\n",
    "#Param:\n",
    "# folder_path: folder path contain data set\n",
    "#Can add check if file is image here but not that necessary\n",
    "def load_data(folder_path):\n",
    "    image_list = []\n",
    "    for filename in glob.glob(\"{}/*.jpg\".format(folder_path)):\n",
    "        im = sk.io.imread(filename) #Image.open(filename)\n",
    "        image_list.append(im)\n",
    "        #im.close()\n",
    "    return image_list\n",
    "\n",
    "#Rotation, can change maximum rotation rate\n",
    "def random_rotation(image_array: ndarray):\n",
    "    random_degree = random.uniform(-45, 45)\n",
    "    return sk.transform.rotate(image_array, random_degree)\n",
    "\n",
    "def random_noise(image_array: ndarray):\n",
    "    return sk.util.random_noise(image_array)\n",
    "\n",
    "def horizontal_flip(image_array: ndarray):\n",
    "    return image_array[:, ::-1]\n",
    "\n",
    "#Augmentation image method given array like image set and save to destination folder\n",
    "#Params:\n",
    "# images: image set\n",
    "# destination_path: path to save augmented image, as desination_path/filename.jpg\n",
    "# num_files_desired: can put 3*length of image set, as there are 3 transformation\n",
    "#Can still get label with new file from the folder name, but can modify to use original file name\n",
    "def data_augmentation(images, destination_path, num_files_desired):\n",
    "    # dictionary of the transformations\n",
    "    available_transformations = {\n",
    "        'rotate': random_rotation,\n",
    "        'noise': random_noise,\n",
    "        'horizontal_flip': horizontal_flip\n",
    "    }\n",
    "    \n",
    "    num_generated_files = 0\n",
    "    while num_generated_files <= num_files_desired:\n",
    "        image_to_transform = random.choice(images)\n",
    "\n",
    "        num_transformations_to_apply = random.randint(1, len(available_transformations))\n",
    "\n",
    "        num_transformations = 0\n",
    "        transformed_image = None\n",
    "        while num_transformations <= num_transformations_to_apply:\n",
    "            key = random.choice(list(available_transformations))\n",
    "            transformed_image = available_transformations[key](image_to_transform)\n",
    "            num_transformations += 1\n",
    "        num_generated_files += 1\n",
    "        new_file_path = '{}/{}.jpg'.format(destination_path, num_generated_files)\n",
    "\n",
    "        io.imsave(new_file_path, transformed_image)\n",
    "\n",
    "#Principle component analysis\n",
    "#Params\n",
    "# X: data set\n",
    "# num_components: Number of component needed, None mean algo will keep everything\n",
    "#Return\n",
    "# Data set after transformation\n",
    "\n",
    "def pca_processing(X, num_components=None):\n",
    "    pca = PCA(n_components=num_components);\n",
    "    X_transformed = pca.fit_transform(X)\n",
    "    #Uncommented to test code by dumping to csv file\n",
    "    #my_df = pd.DataFrame(X_transformed)\n",
    "    #my_df.to_csv('pca.csv', index=False) \n",
    "    return X_transformed\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"train/train\"\n",
    "augmentation_path = \"augmented\"\n",
    "test_path = \"test\"\n",
    "\n",
    "#Example on how to load data, resize, augmented from all folder in trains\n",
    "data_original = []\n",
    "data_augmented = []\n",
    "\n",
    "for i in range(0, 41):\n",
    "    folder_path = join(train_path, str(i).zfill(2))\n",
    "    augmented_folder_path = join(augmentation_path, str(i).zfill(2))\n",
    "    \n",
    "    resize(folder_path, 300) #resize all to 300 x 300 image\n",
    "    \n",
    "    temp = load_data(folder_path)\n",
    "    data_original += temp\n",
    "    data_augmentation(temp, augmented_folder_path, len(temp)*3) #apply all 3 transformation to all images\n",
    "    data_augmented += load_data(augmented_folder_path)\n",
    "    \n",
    "#To apply pca for testing, need to safe current PCA weights and multiply with current instance before feed to model\n",
    "pca_input = np.array(data_augmented)\n",
    "pca_input = pca_input.reshape(pca_input.shape[0], pca_input.shape[1]*pca_input.shape[2]*pca_input.shape[3]) #flatten image by reshape\n",
    "X_transformed = pca_processing(pca_input, 7500) #reduce from 300*300*3 dimension to 50*50*3 dimension \n",
    "\n",
    "#Can further applytechnique like normalizing, feature scaling before give data to model input \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
